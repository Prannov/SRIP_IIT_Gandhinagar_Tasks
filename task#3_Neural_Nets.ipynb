{"cells":[{"cell_type":"markdown","source":["#Implement two hidden layers neural network classifier from scratch in JAX\n"],"metadata":{"id":"DItDhcLyhvMJ"}},{"cell_type":"markdown","source":["##1. Importing Libraries: numpy, jax, PyTorch\n","\n","  PyTorch libraries for MNIST dataset and creating a DataLoader"],"metadata":{"id":"uW6yNSVdh3Bm"}},{"cell_type":"code","source":["import numpy as np\n","import jax\n","import jax.numpy as jnp\n","from jax.scipy.special import logsumexp\n","from jax import jit, vmap, pmap, grad, value_and_grad\n","\n","from torchvision.datasets import MNIST\n","from torch.utils.data import DataLoader"],"metadata":{"id":"pi3zOJn8coFz","executionInfo":{"status":"ok","timestamp":1649567379087,"user_tz":-330,"elapsed":412,"user":{"displayName":"Prannov Jamadagni","userId":"03364511168961466703"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["##2. Multi Layer Perceptron (MLP) Initialisation"],"metadata":{"id":"6o11p4BNiPL7"}},{"cell_type":"code","source":["seed = 0\n","mnist_img_size = (28, 28)\n","\n","#initialising a multi-layered perceptron\n","def init_MLP(layer_widths,parent_key,scale = 0.01):\n","  params = []\n","  keys = jax.random.split(parent_key, num = len(layer_widths)-1)\n","  \n","  for in_width, out_width, key in zip(layer_widths[:-1], layer_widths[1:], keys):\n","    weight_key, bias_key = jax.random.split(key)\n","    params.append([\n","            scale * jax.random.normal(weight_key, shape = (out_width,in_width)), \n","            scale * jax.random.normal(bias_key, shape = (out_width,))\n","            ] \n","    )\n","  return params\n","\n","#testing function\n","key = jax.random.PRNGKey(seed)\n","\n","MLP_params = init_MLP([784,512,256,10],key)\n","print(jax.tree_map(lambda x: x.shape, MLP_params))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-dVfp0jcrRD","executionInfo":{"status":"ok","timestamp":1649567025838,"user_tz":-330,"elapsed":5,"user":{"displayName":"Prannov Jamadagni","userId":"03364511168961466703"}},"outputId":"24c238f4-ec39-4e6a-a23d-5dee87ce533e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[(512, 784), (512,)], [(256, 512), (256,)], [(10, 256), (10,)]]\n"]}]},{"cell_type":"markdown","source":["##3. Prediction Function\n","\n","Creating two hidden layers and using 'relu' as an activation function. \n","\n","activation := dot product[(weights)(activation)] + bias"],"metadata":{"id":"mBvZgKTyiy_J"}},{"cell_type":"code","source":["#creating prediction function\n","def MLP_predict(params, x):\n","  hidden_layers = params[:-1]\n","\n","  activation = x\n","  for w,b in hidden_layers:\n","    activation = jax.nn.relu(jnp.dot(w,activation)+b)\n","\n","  w_last, b_last = params[-1]\n","  logits = jnp.dot(w_last,activation)+b_last\n","\n","  return logits - logsumexp(logits)\n","\n","batched_MLP_predict = vmap(MLP_predict, in_axes=(None, 0))\n","\n","dummy_imgs_flat = np.random.randn(16, np.prod(mnist_img_size))\n","print(dummy_imgs_flat.shape)\n","predictions = batched_MLP_predict(MLP_params, dummy_imgs_flat)\n","print(predictions.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XvYt7AfkeL2Y","executionInfo":{"status":"ok","timestamp":1649568716676,"user_tz":-330,"elapsed":1390,"user":{"displayName":"Prannov Jamadagni","userId":"03364511168961466703"}},"outputId":"de6c80b0-608b-4bb1-de81-f8d5f6aaa11f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["(16, 784)\n","(16, 10)\n"]}]},{"cell_type":"markdown","source":["##4. Data Collection from MNIST Dataset\n","\n","Creating a transform and collate function to properly shape the data.\n","\n","Testing it with the batched data and optimising it for better performance"],"metadata":{"id":"AE-K0OtqjVy5"}},{"cell_type":"code","source":["def custom_transform(x):\n","    return np.ravel(np.array(x, dtype=np.float32))\n","\n","def custom_collate_fn(batch):\n","    transposed_data = list(zip(*batch))\n","\n","    labels = np.array(transposed_data[1])\n","    imgs = np.stack(transposed_data[0])\n","\n","    return imgs, labels\n","\n","batch_size = 128\n","train_dataset = MNIST(root='train_mnist', train=True, download=True, transform=custom_transform)\n","test_dataset = MNIST(root='test_mnist', train=False, download=True, transform=custom_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n","test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)\n","\n","# test\n","batch_data = next(iter(train_loader))\n","imgs = batch_data[0]\n","lbls = batch_data[1]\n","print(imgs.shape, imgs[0].dtype, lbls.shape, lbls[0].dtype)\n","\n","# optimization\n","train_images = jnp.array(train_dataset.data).reshape(len(train_dataset), -1)\n","train_lbls = jnp.array(train_dataset.targets)\n","\n","test_images = jnp.array(test_dataset.data).reshape(len(test_dataset), -1)\n","test_lbls = jnp.array(test_dataset.targets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Xl3f-TBs8vw","executionInfo":{"status":"ok","timestamp":1649569121692,"user_tz":-330,"elapsed":411,"user":{"displayName":"Prannov Jamadagni","userId":"03364511168961466703"}},"outputId":"586e478d-fec4-47bd-f834-4700d78871ec"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["(128, 784) float32 (128,) int64\n"]}]},{"cell_type":"markdown","source":["##5. Loss function, Accuracy function, Update Function\n","\n","Loss function takes MLP parameters, images and the labels as parameters and returns the loss value.\n","\n","Accuracy function returns the total correct predictions for all the predictions. \n","\n","Update function uses gradient descent with the help of \"tree_multimap\" from the JAX library.\n","\n","The number of epochs are set to 5 for faster computation.\n","\n","Therefore, the loop is trained with the help of these three functions."],"metadata":{"id":"Z2UO6eL8jz5i"}},{"cell_type":"code","source":["num_epochs = 5\n","\n","def loss_fn(params, imgs, gt_lbls):\n","    predictions = batched_MLP_predict(params, imgs)\n","\n","    return -jnp.mean(predictions * gt_lbls)\n","\n","def accuracy(params, dataset_imgs, dataset_lbls):\n","    pred_classes = jnp.argmax(batched_MLP_predict(params, dataset_imgs), axis=1)\n","    return jnp.mean(dataset_lbls == pred_classes)\n","\n","@jit\n","def update(params, imgs, gt_lbls, lr=0.01):\n","    loss, grads = value_and_grad(loss_fn)(params, imgs, gt_lbls)\n","\n","    return loss, jax.tree_multimap(lambda p, g: p - lr*g, params, grads)\n","\n","MLP_params = init_MLP([np.prod(mnist_img_size), 512, 256, len(MNIST.classes)], key)\n","\n","for epoch in range(num_epochs):\n","\n","    for cnt, (imgs, lbls) in enumerate(train_loader):\n","\n","        gt_labels = jax.nn.one_hot(lbls, len(MNIST.classes))\n","        \n","        loss, MLP_params = update(MLP_params, imgs, gt_labels)\n","        \n","        if cnt % 50 == 0:\n","            print(loss)\n","\n","    print(f'Epoch {epoch}, train acc = {accuracy(MLP_params, train_images, train_lbls)} test acc = {accuracy(MLP_params, test_images, test_lbls)}')\n"],"metadata":{"id":"fo-lMg2Kw-rb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##6. Sample visualisation and prediction of the model\n","\n","Here, a random image from the test set is used to predict. \n","With the help of \"matplotlib\" library, it is shown that the the predicted result and labeled value is the same."],"metadata":{"id":"3a8Oyny1k6pN"}},{"cell_type":"code","source":["imgs,lbls = next(iter(test_loader))\n","img = imgs[7].reshape(mnist_img_size)\n","gt_lbl = lbls[7]\n","print(img.shape)\n","\n","import matplotlib.pyplot as plt\n","\n","pred = jnp.argmax(MLP_predict(MLP_params, np.ravel(img)))\n","print('predicted: ', pred)\n","print('gt: ', gt_lbl)\n","plt.imshow(img)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"V9ZSTLtD07q1","executionInfo":{"status":"ok","timestamp":1649570019975,"user_tz":-330,"elapsed":417,"user":{"displayName":"Prannov Jamadagni","userId":"03364511168961466703"}},"outputId":"50b2d91e-50dc-4de5-b4cd-64d65b60c181"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["(28, 28)\n","predicted:  9\n","gt:  9\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["##7. Checking the accuracy score of the model for both training and testing set"],"metadata":{"id":"C3dTF0ftl2-s"}},{"cell_type":"code","source":["train_accuracy = accuracy(MLP_params, train_images, train_lbls) \n","test_accuracy = accuracy(MLP_params, test_images, test_lbls)\n","print(train_accuracy)\n","print(test_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5hsPrFHaD82D","executionInfo":{"status":"ok","timestamp":1649571579086,"user_tz":-330,"elapsed":370,"user":{"displayName":"Prannov Jamadagni","userId":"03364511168961466703"}},"outputId":"47bca0ca-93e7-485e-a549-5990f5bd5988"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9607667\n","0.95589995\n"]}]},{"cell_type":"markdown","source":["The model created is an example of a multi-layered perceptron. This model is created with two hidden layers. The weights and biases are taken to be random numbers using the jax.random. \n","\n","The neural networks are then initialised with the vmap() function from the JAX library. This function helped in batching the complete predict() function in this experiment.\n","\n","The neurons in each layer are manually optimised with the help of jnp.array() function. \n","\n","Finally, the accuracy of the model is <b>96.07%</b> for the <b>training set</b> and <b>95.59%</b> for the <b> test set</b>. "],"metadata":{"id":"86ZiDMoJl42R"}},{"cell_type":"markdown","source":["## Missing work\n","1. The <b>loss v/s iteration curve</b> was difficult to make as creating the training model for each epoch required using optax library.\n","\n","2. The analysis using different <b>Classification Metrics</b> was not done due to errors while creating functions for each metric. Moreover, the metrics part required use of other libraries like sklearn. Module called as sklearn.metrics can be used for the Classification purposes.\n","\n","Due to the above reasons, loss/iteration graph and classification metrics were not done."],"metadata":{"id":"SELPtqfnnrwZ"}},{"cell_type":"markdown","source":["##References\n","1. JAX Documentation: https://jax.readthedocs.io/en/latest/notebooks/quickstart.html\n","2. PyTorch Utils: https://pytorch.org/docs/stable/data.html\n","\n","3. SciPy Special Module: https://docs.scipy.org/doc/scipy/reference/special.html\n","4. Neural Network Fundamentals from www.deeplearning.ai articles and blogs.\n","\n","5. Kaggle(www.kaggle.com) Code for better undestanding of using JAX library.\n","\n","6. AI Epiphany Youtube Channel (www.youtube.com) for learning basics of JAX library and its modules. \n"],"metadata":{"id":"LPVIPnSqpWqk"}}],"metadata":{"colab":{"name":"task#3_Neural_Nets.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOL/5m+5apLzhKNlwQ6svju"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}